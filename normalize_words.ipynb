{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "normalize_words.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmrANC1N2ZJ+jc+D0es48i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svyatoslavn1000/data_science_np_pd/blob/main/normalize_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYy2G-diPlj2",
        "outputId": "f3ec5a97-7ba2-49e4-bb4c-85fc3ebead48"
      },
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "corpus = [\n",
        "    'Казнить нельзя, помиловать. Нельзя наказывать.',\n",
        "    'Казнить, нельзя помиловать. Нельзя освободить.',\n",
        "    'Нельзя не помиловать.',\n",
        "    'Обязательно освободить.']\n",
        "\n",
        "#Получаем счетчики слов\n",
        "TF = CountVectorizer().fit_transform(corpus)\n",
        "\n",
        "#Строим IDF. К сожалению, в этом задании нам нужно только vectorizer.idf_\n",
        "#Для стандартных случаев на этой строке все вычисления и заканчиваются.\n",
        "#Обычно  TFIDF = vectorizer.fit_transform(corpus)\n",
        "vectorizer = TfidfVectorizer(smooth_idf=False, use_idf=True)\n",
        "vectorizer.fit_transform(corpus)\n",
        "\n",
        "## из IDF  в DF\n",
        "word_doc_freq = 1/np.exp(vectorizer.idf_ - 1)\n",
        "\n",
        "#TF нормируем и сглаживаем логарифмом (требование задания)\n",
        "TFIDF = np.log(TF/TF.sum(axis=1)+1) / word_doc_freq \n",
        "\n",
        "#Масштабируем признаки\n",
        "scaledTFIDF = StandardScaler().fit_transform(TFIDF)\n",
        "\n",
        "#Домножаем на np.sqrt((4-1)/4) для перевода из DDOF(0) в DDOF(1) для 4 текстов\n",
        "#(требование задания) \n",
        "scaledTFIDF *= np.sqrt(3/4)\n",
        "\n",
        "#Вывод в порядке возрастания DF\n",
        "for l in scaledTFIDF[:,np.argsort(word_doc_freq)]:\n",
        "    print (\" \".join([ \"%.2f\" % d for d in l]))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.50 -0.50 -0.50 0.87 -0.76 0.60 0.16\n",
            "-0.50 -0.50 -0.50 0.87 0.18 0.60 0.16\n",
            "-0.50 1.50 -0.50 -0.87 -0.76 0.29 1.04\n",
            "-0.50 -0.50 1.50 -0.87 1.34 -1.48 -1.36\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}